APP_NAME=Laravel
APP_ENV=local
APP_KEY=
APP_DEBUG=true
APP_URL=http://localhost

APP_LOCALE=en
APP_FALLBACK_LOCALE=en
APP_FAKER_LOCALE=en_US

APP_MAINTENANCE_DRIVER=file
# APP_MAINTENANCE_STORE=database

PHP_CLI_SERVER_WORKERS=4

BCRYPT_ROUNDS=12

LOG_CHANNEL=stack
LOG_STACK=single
LOG_DEPRECATIONS_CHANNEL=null
LOG_LEVEL=debug

DB_CONNECTION=sqlite
# DB_HOST=127.0.0.1
# DB_PORT=3306
# DB_DATABASE=laravel
# DB_USERNAME=root
# DB_PASSWORD=

SESSION_DRIVER=database
SESSION_LIFETIME=120
SESSION_ENCRYPT=false
SESSION_PATH=/
SESSION_DOMAIN=null

BROADCAST_CONNECTION=log
FILESYSTEM_DISK=local
QUEUE_CONNECTION=database

CACHE_STORE=database
# CACHE_PREFIX=

MEMCACHED_HOST=127.0.0.1

REDIS_CLIENT=phpredis
REDIS_HOST=127.0.0.1
REDIS_PASSWORD=null
REDIS_PORT=6379

MAIL_MAILER=log
MAIL_SCHEME=null
MAIL_HOST=127.0.0.1
MAIL_PORT=2525
MAIL_USERNAME=null
MAIL_PASSWORD=null
MAIL_FROM_ADDRESS="hello@example.com"
MAIL_FROM_NAME="${APP_NAME}"

AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_DEFAULT_REGION=us-east-1
AWS_BUCKET=
AWS_USE_PATH_STYLE_ENDPOINT=false

# Machine Learning Prediction API Configuration
# -----------------------------------------------------------------------------
# Scalable ML API with database integration and caching
#
# Basic Settings:
PREDICTION_API_URL=http://localhost:5000
PREDICTION_API_TIMEOUT=30

# Prediction Limits:
MAX_PREDICTIONS=12

# ML API Caching (Laravel side):
# Enable caching for ML API responses to improve performance
ML_API_CACHE_ENABLED=true
ML_API_CACHE_TTL=300

# ML API Database Settings:
# These should match your ML API .env configuration
# The ML API can use a shared database with Laravel or separate database
# USE_DATABASE=true                    # Enable database in ML API
# FALLBACK_TO_FILES=true               # Fallback to CSV if database fails
# DATABASE_TYPE=mysql                  # mysql or postgresql
# DATABASE_HOST=127.0.0.1
# DATABASE_PORT=3306
# DATABASE_NAME=pasya_ml
# DATABASE_USER=root
# DATABASE_PASSWORD=

# ML API Caching (ML API side):
# CACHE_ENABLED=true                   # Enable caching in ML API
# CACHE_TYPE=memory                    # memory or redis
# CACHE_TTL_CROPS=3600
# CACHE_TTL_MUNICIPALITIES=3600
# CACHE_TTL_FORECASTS=3600
# CACHE_TTL_PREDICTIONS=300

# Redis Configuration (if using Redis for ML API caching):
# REDIS_HOST=127.0.0.1
# REDIS_PORT=6379
# REDIS_DB=0
# REDIS_PASSWORD=

# ML API Logging:
# LOG_LEVEL=INFO                       # DEBUG, INFO, WARNING, ERROR
# LOG_PREDICTIONS=true                 # Log all predictions to database

VITE_APP_NAME="${APP_NAME}"

